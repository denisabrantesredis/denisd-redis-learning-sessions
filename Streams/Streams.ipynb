{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09X5wKjBIsT"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/Streams.ipynb\" target=\"_newt\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tk5ymdLBTeq"
      },
      "source": [
        "<div style=\"display:flex;width=100%;\">\n",
        "<img src=\"https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120\" alt=\"Redis\" width=\"90\"/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "</div>\n",
        "\n",
        "# Redis Learning Session - Streams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/banner.png?raw=true\" alt=\"Redis Data Types\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8w5OAHNOlFf"
      },
      "source": [
        "[Try a streams payment monitoring demo application](https://github.com/gacerioni/redis-mvp-lists-fifo)\n",
        "\n",
        "In this notebook, we will explore the Streams capabilities provided by Redis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENspmGoTR6tq"
      },
      "source": [
        "## Installing the Pre-Reqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFmBBQ0bBFym"
      },
      "outputs": [],
      "source": [
        "!pip install -q redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing Redis Locally\n",
        "If you are not using Redis Cloud as a database, uncomment and run the code below to install Redis locally. Then set your connection to 127.0.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%sh\n",
        "# sudo apt-get install lsb-release curl gpg\n",
        "# curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "# sudo chmod 644 /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "# echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "# sudo apt-get update\n",
        "# sudo apt-get install redis > /dev/null 2>&1\n",
        "# redis-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connecting to Redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import redis\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Setup the Connection String"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/callout_secrets.png?raw=true\" alt=\"Callout - Use Google Colab secrets instead\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  REDIS_HOST = userdata.get('REDIS_HOST')\n",
        "except:\n",
        "  REDIS_HOST=\"127.0.0.1\"\n",
        "\n",
        "try:\n",
        "  REDIS_PORT = userdata.get('REDIS_PORT')\n",
        "except:\n",
        "  REDIS_PORT=6379\n",
        "\n",
        "try:\n",
        "  REDIS_PASSWORD = userdata.get('REDIS_PASSWORD')\n",
        "except:\n",
        "  REDIS_PASSWORD=\"\"\n",
        "\n",
        "REDIS_URL = f\"redis://default:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing the Connection to Redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/callout_connection.png?raw=true\" alt=\"Callout - Make sure connection works\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = redis.from_url(REDIS_URL, decode_responses=True)\n",
        "\n",
        "if r.ping():\n",
        "    print(\"Connection successful!\")\n",
        "else:\n",
        "    print(\"Connection issue!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7_A4sOeDfqt"
      },
      "source": [
        "## Inserting Messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ6RwklAct5K"
      },
      "source": [
        "Streams are an append-only data structure. The fundamental write command, called XADD, appends a new entry to the specified stream. If the specified stream does not exist, it gets created automatically by the command.\n",
        "\n",
        "Each stream entry consists of one or entries (messages) with field-value pairs (somewhat like a dictionary or a Redis hash). Each message needs a unique identifier, which can be determined by the Redis server by passing the `*` character as the message ID. This causes the Redis server to generate a new ID which is a combination of current timestamp (at the millisecond level) and a unique sequence number.\n",
        "\n",
        "Every new ID will be monotonically increasing, so in more simple terms, every new entry added will have a higher ID compared to all the past entries. Auto-generation of IDs by the server is almost always the desired approach, and the reasons for specifying an ID explicitly are very rare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ko4lH56BFs3"
      },
      "outputs": [],
      "source": [
        "r.xadd(\"mystream\", id=\"*\", fields={\"sensor_id\": 1234, \"temperature\": 19.8})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Print Stream information\n",
        "\n",
        "Here we can find the key that contains the `mystream` stream, and we can see how many messages it has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD3zIcq6BFpx"
      },
      "outputs": [],
      "source": [
        "print(r.keys(\"my*\"))\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we add a few more entries to the stream and check the size again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r.xadd(\"mystream\", id=\"*\", fields={\"vehicle_id\": 1, \"name\": \"my cool car\", \"price\": 20000})\n",
        "r.xadd(\"mystream\", id=\"*\", fields={\"vehicle_id\": 2, \"name\": \"my old car\", \"price\": 100})\n",
        "r.xadd(\"mystream\", id=\"*\", fields={\"vehicle_id\": 3, \"name\": \"my family car\", \"price\": 1000})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.keys(\"my*\"))\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open Redis Insight and confirm that the Stream key was generated. There should be only one key, called `mystream`, which contains all the 4 entries we generated, since no consumer has processed these messages yet.\n",
        "\n",
        "Needless to say, we shouldn't be inserting completely different messages to the same stream; we will fix that in a bit.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading Messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are multiple ways to read data from Redis Streams: consumer apps can request all entries from the beginning of a stream; they can search for a subset of entries within specific time ranges (which is why the default ID is timestamp-based) or they can just get entries that are new since the last entry they received.\n",
        "\n",
        "This diversity allows Streams to be used in different ways, to solve for different use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Read all messages from a stream\n",
        "\n",
        "Here we are using the special operators `-` and `+` to instruct Redis to provide all entries in a stream, from beginning to end.\n",
        "\n",
        "PS: this operation is not recommended for large streams, as retrieval might take too much time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xrange(\"mystream\", \"-\", \"+\")\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the field names are identical between entries, Streams will only store this data once, to optimize space usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another option for this command is to start at the first entry. If the ID of the first entry is unknown, you can use the `0` character instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xrange(\"mystream\", 0, \"+\")\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also limit the number of retrieved entries using the `count` parameter. Notice that in this case, retrieval starts from the beginning of the stream."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xrange(\"mystream\", \"-\", \"+\", count=2)\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Retrieve specific entries\n",
        "\n",
        "The `xrange` command can be used to retrieve a specific subset of entries, based on ID and count. In the Search lab, we saw how we can return 30 entries of IoT metrics from Streams, using the `xrange` command.\n",
        "\n",
        "First, let's repeat the last command, but save the ID of the last message retrieved:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xrange(\"mystream\", \"-\", \"+\", count=2)\n",
        "\n",
        "message_id = all_entries[len(all_entries)-1][0]\n",
        "message_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, retrieve 2 more entries, starting at this ID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xrange(\"mystream\", message_id, \"+\", count=2)\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Reverse Retrieval\n",
        "\n",
        "The `xrevrange` command can be used to retrieve entries in reverse, from newer to older. This can be useful for requirements like 'retrieve the last 10 entries':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xrevrange(\"mystream\", message_id, \"-\", count=3)\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how, even though we specified `count=3`, there is only 1 other entry older than our `message_id`, so the command only returns 2 entries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Cq6TN1DrIk"
      },
      "source": [
        "## Listening for new messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33RhGtaaduow"
      },
      "source": [
        "<b>IMPORTANT</b>: This will only work if you are using an external Redis Database (like Redis Cloud) and if you have Redis Insight configured.\n",
        "\n",
        "The `xread` command will listen to new entries that are published to a stream. It can run indefinitely (which is not recommended), or within a timeout.\n",
        "\n",
        "For this lab, we will be using the following paramters:\n",
        "\n",
        "- `count=1`: the client will receive 1 entry at a time\n",
        "\n",
        "- `block=2000`: the command will listen for new entries for a total of 2,000 milliseconds (2 seconds). Notice that the client will be blocked while it's listening, which is why this exercise won't work if you are using Redis inside the notebook; you won't be able to create new entries while the client is listening, because this is a blocking operation.\n",
        "\n",
        "- `streams={\"mystream\": '$'}`: the dollar sign instructs Redis to only send new entries to the client, emulating the behavior of Pub/Sub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHd7FtUPBFlE"
      },
      "outputs": [],
      "source": [
        "l = r.xread( count=1, block=2000, streams={\"mystream\": '$'} )\n",
        "print( f\"after 2s block, got this: {l}\")\n",
        "print( f\"stream length: {r.xlen(\"mystream\")}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After this command, nothing will happen, because there is no Producer app sending new entries. We can use Redis Insight to emulate a producer.\n",
        "\n",
        "First, make sure Redis Insight is connected to the database. Then, go to the Workbench and paste the following command (<b>but don't run it yet!</b>):\n",
        "\n",
        "`XADD mystream * vehicle_id 4 name 'my work car' price 50000`\n",
        "\n",
        "Then, run the same command as before, but increase it to 10 seconds. While it's running, go to Insights and run the command above to create the new entry."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvoJfpupBFf2"
      },
      "outputs": [],
      "source": [
        "l = r.xread( count=1, block=10000, streams={\"mystream\": '$'} )\n",
        "print( f\"after 10s block, got this: {l}\")\n",
        "print( f\"stream length: {r.xlen(\"mystream\")}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output will show the new entry and the updated stream length of 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Consumer Groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A consumer group is used to retrieve data from a stream, serving multiple consumers, while providing certain guarantees:\n",
        "\n",
        "- Each message is served to a different consumer so that it is not possible that the same message will be delivered to multiple consumers.\n",
        "\n",
        "- Consumers are identified, within a consumer group, by a name. This means that even after a disconnect, the stream consumer group retains all the state, since the client will claim again to be the same consumer.\n",
        "\n",
        "- Each consumer group has the concept of the first ID never consumed so that, when a consumer asks for new messages, it can provide just messages that were not previously delivered.\n",
        "\n",
        "- Consuming a message, however, requires an explicit acknowledgment using a specific command. Redis interprets the acknowledgment as: this message was correctly processed so it can be evicted from the consumer group.\n",
        "\n",
        "- A consumer group tracks all the messages that are currently pending, that is, messages that were delivered to some consumer of the consumer group, but are yet to be acknowledged as processed. Thanks to this feature, when accessing the message history of a stream, each consumer will only see messages that were delivered to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Housekeeping: Trimming the stream\n",
        "\n",
        "Since we have messages in different formats in our stream, let's empty the stream before we continue.\n",
        "\n",
        "The `xtrim` command is used to limit the size of a stream, by deleting older entries. It can be configured in different ways to support different requirements. In this case, we'll use the `maxlen=0` parameter to tell Redis to completely empty the stream."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xtrim(\"mystream\", maxlen=0))\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output for the first command (4) shows how many entries were removed (trimmmed)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use Redis Insight to check on the stream data. The `mystream` key should still be there, but it should be empty now. Also, the 2 Consumer Groups we created should also be there, but with 0 consumers and 0 pending entries listed.\n",
        "\n",
        "&nbsp;\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZkC5BMHEBit"
      },
      "source": [
        "#### Creating Consumer Groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's create a few new messages to populate our stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 1, \"message\": \"apple\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 2, \"message\": \"orange\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 3, \"message\": \"strawberry\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 4, \"message\": \"apricot\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 5, \"message\": \"banana\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 6, \"message\": \"banana\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 7, \"message\": \"banana\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 8, \"message\": \"banana\"}))\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's create 2 consumer groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJdvZR-FEIcE"
      },
      "outputs": [],
      "source": [
        "print(r.xgroup_create(\"mystream\", \"myGroupFromStart\", 0))\n",
        "\n",
        "print(r.xgroup_create(\"mystream\", \"myGroupFromEnd\", \"$\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These 2 groups will behave differently: `myGroupFromStart` will receive all entries for that stream, since the first one (because it's using the `0` character), while `myGroupFromEnd` will only receive new entries, since it's using the dollar sign in its definition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-_RvOKmVr7"
      },
      "source": [
        "## Reading Entries as a Consumer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `xreadgroup` command is similar to the `xread` command, but it was designed to work with Consumer Groups. This is how we can ensure that 2 consumers in the same group will not retrieve the same entries, for instance.\n",
        "\n",
        "Let's start by having a consumer called `Alice` retrieving 1 entry from the stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0H9huxKHI4q"
      },
      "outputs": [],
      "source": [
        "all_entries = r.xreadgroup(\"myGroupFromStart\", consumername=\"Alice\", count=1, streams={\"mystream\":'>'})\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Y3Fy_JnSm5"
      },
      "source": [
        "Here we retrieved the first entry. As discussed in the session, this entry is now in the Pending Entries List, and we can check that by running the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLUdjv5KHOpJ"
      },
      "outputs": [],
      "source": [
        "print(r.xpending(\"mystream\", \"myGroupFromStart\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_j8oVZIzgvv"
      },
      "source": [
        "Notice that the output includes which consumer currently 'owns' the entry.\n",
        "\n",
        "It will stay there until it is acknowledged by the consumer (`Alice`, or another one, if the entry is pending for too long and the consumers have logic to retrieve pending entries).\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Next, let's have another consumer in the same group (call this one `Bob`) retrieve an entry:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g-MMhPNze4Z"
      },
      "outputs": [],
      "source": [
        "all_entries = r.xreadgroup(\"myGroupFromStart\", consumername=\"Bob\", count=1, streams={\"mystream\":'>'})\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even though `Bob` ran the same exact command as `Alice`, it received the second entry in the stream, seeing as the first one is currently being processed by `Alice`. This is controlled by the `>` character, that is used to determine that Redis should only send entries that have not yet been delivered to any consumers.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Let's now have our consumer `Alice` retrieving another entry from the stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xreadgroup(\"myGroupFromStart\", consumername=\"Alice\", count=1, streams={\"mystream\":'>'})\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The 3rd entry on the stream was retrieved by this command.\n",
        "\n",
        "Now, let's see what happens when we try to get an entry for the `myGroupFromEnd` consumer group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xreadgroup(\"myGroupFromEnd\", consumername=\"Mary\", count=1, streams={\"mystream\":'>'})\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It returns no results, because there are no entries inserted after the consumer group was created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pending Entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are multiple ways entries can be handled once they are delivered to a consumer:\n",
        "\n",
        "- They can be acknowledged and kept (permanently or until they are trimmed);\n",
        "\n",
        "- They can be acknowledged and deleted;\n",
        "\n",
        "- Crashed consumers can re-connect to Redis, check their pending entries and resume processing;\n",
        "\n",
        "- A monitoring process can reassign pending entries to other consumers if it's taking too long to process;\n",
        "\n",
        "- Other consumers can proactively find and claim pending entries.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "The `xpending_range` command can be used to provide a list of pending entries for a Consumer Group in a stream, along with the length of time since the message was delivered, and a counter of how many times this message was delivered (which is extremely useful to identify 'poison pill' entries, which are payloads that cannot be processed and keep being bounced around between consumers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pending_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 10)\n",
        "\n",
        "for entry in pending_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because we've used the `-` and `+` operators here, we are retrieving all pending messages (to a maximum of 10), from the beginning of the stream. It's possible to narrow down this command and use specific IDs (timestamps) to further refine the search.\n",
        "\n",
        "It's also possible to narrow down this command to a single consumer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pending_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 10, \"Alice\")\n",
        "\n",
        "for entry in pending_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Claiming Entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entries can be claimed by (or on behalf of) other consumers. Let's say, for instance, that our `Alice` consumer is having problems, so we want to reassign all of Alice's pending tasks to the `Bob` consumer.\n",
        "\n",
        "First, we create a list with all the entry IDs that are pending for `Alice`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pending_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 10, \"Alice\")\n",
        "alice_entries = []\n",
        "\n",
        "for entry in pending_entries:\n",
        "  alice_entries.append(entry['message_id'])\n",
        "\n",
        "print(alice_entries)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we assign these entries to `Bob`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xclaim(name=\"mystream\", \n",
        "               groupname=\"myGroupFromStart\", \n",
        "               consumername=\"Bob\", \n",
        "               min_idle_time=360, \n",
        "               message_ids=alice_entries)\n",
        "               )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that we are using the `xclaim` command, passing the list of message IDs. However, we are also setting the `min_time_idle` parameter. There are 2 reasons why we do that:\n",
        "\n",
        "1 - We don't want to risk reassigning entries that are still actively being processed (because the `xpending_range` command might have been issued 1 ms after the entry was created); and\n",
        "\n",
        "2 - The `xclaim` command resets the `time_since_delivered` parameters, which means that if 2 consumers try to claim the same entry, the first will succeed, but the second will fail, because `min_idle_time` will be lower than the input parameter.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "Finally, check the list of pending entries again, and we should see that all pending entries are now with the `Bob` consumer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pending_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 10)\n",
        "\n",
        "for entry in pending_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To simplify this process, you can use the `XAUTOCLAIM` command, which finds pending entries and claims them automatically, without the need to produce a list of `message_ids`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHy0dVgsAAg"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDX0QOboqped"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBu0RKZqu4t"
      },
      "source": [
        "Check the stream in Redis Insight, you can go to the Consumer Groups tab and click on myGroupFromStart to see the consumers and their pending entries. Bob should be showing 3, while Alice shows 0.\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__zfLJoaHa13"
      },
      "source": [
        "## Acknowledging Entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjpqcmh8vGFP"
      },
      "source": [
        "Once an entry has been processed, it can be acknowledged by the consumer, so it will be removed from the Pending Entries List. \n",
        "\n",
        "There are different ways to handle acknowledge entries: if they need to be processed by other consumer groups, they can be acknowledged and removed from the Pending Entries List for this consumer group, but not others. If they don't need further processing, they can be acknowledged and deleted from all consumer groups; if they are needed for audit purposes, they can be acknowledged and kept permanently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's add a few new entries to our stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\":  9, \"message\": \"pear\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 10, \"message\": \"pineapple\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 11, \"message\": \"watermelon\"}))\n",
        "print(r.xadd(\"mystream\", id=\"*\", fields={\"id\": 12, \"message\": \"peach\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's create a couple of consumers on the other consumer group (`myGroupFromEnd`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-n9ER0lHi12"
      },
      "outputs": [],
      "source": [
        "all_entries = r.xreadgroup(\"myGroupFromEnd\", consumername=\"Mary\", count=1, streams={\"mystream\":'>'})\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_entries = r.xreadgroup(\"myGroupFromEnd\", consumername=\"John\", count=1, streams={\"mystream\":'>'})\n",
        "\n",
        "for entry in all_entries:\n",
        "  print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that they received the new entries, instead of the entries that were already in the stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FKaU45iwULg"
      },
      "source": [
        "#### Delivering all entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To explore the different acknowledgment options, we need to make sure all entries are delivered to a consumer. Let's run this loop that will ensure that all entries get delivered:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wepEg9G0umFH"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  r.xreadgroup(\"myGroupFromStart\", consumername=\"Alice\", count=1, streams={\"mystream\":'>'})\n",
        "  r.xreadgroup(\"myGroupFromStart\", consumername=\"Bob\", count=1, streams={\"mystream\":'>'})\n",
        "  r.xreadgroup(\"myGroupFromEnd\", consumername=\"Mary\", count=1, streams={\"mystream\":'>'})\n",
        "  r.xreadgroup(\"myGroupFromEnd\", consumername=\"John\", count=1, streams={\"mystream\":'>'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, check the size of the stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And check that every entry was delivered to a consumer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  print(entry)\n",
        "\n",
        "for entry in group2_entries:\n",
        "  print(entry)\n",
        "\n",
        "print(f\"\\n Total: {len(group1_entries) + len(group2_entries)} pending entries.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the `myGroupFromEnd` consumer group will only receive the 4 new entries we've created, while the `myGroupFromStart` consumer group will receive all. So the final count of pending entries will be higher than the size of the stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Acknowledging entries for one consumer group\n",
        "\n",
        "In this first example, we'll acknowledge the first entry delivered to the `myGroupFromEnd` consumer group, making sure not to delete it, so it can still be processed by the `myGroupFromStart` consumer.\n",
        "\n",
        "First, we need to grab the message ID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pending_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 10, \"Mary\")\n",
        "message_id = pending_entries[0]['message_id']\n",
        "print(message_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we use the `XACK` command, which removes one or more messages from the Pending Entries List (PEL) of a stream consumer group. A message is marked as 'pending' when it was delivered to some consumer but the server is yet not sure it was processed at least once. \n",
        "\n",
        "Once a consumer successfully processes a message, it should call XACK so that such message does not get processed again, and as a side effect, the PEL entry about this message is also purged, releasing memory from the Redis server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xack(\"mystream\", \"myGroupFromEnd\", message_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, check if the message still appears in the Pending Entries List for both consumer groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  print(entry)\n",
        "\n",
        "for entry in group2_entries:\n",
        "  print(entry)\n",
        "\n",
        "print(f\"\\n Total: {len(group1_entries) + len(group2_entries)} pending entries - message {message_id} should have been removed from the myGroupFromEnd consumer group.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the entry is still waiting to be processed by the consumer from the `myGroupFromStart` consumer group.\n",
        "\n",
        "Let's acknowledge the message in the other consumer group as well:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xack(\"mystream\", \"myGroupFromStart\", message_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's check our pending entries again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  print(entry)\n",
        "\n",
        "for entry in group2_entries:\n",
        "  print(entry)\n",
        "\n",
        "print(f\"\\n Total: {len(group1_entries) + len(group2_entries)} pending entries - message {message_id} should have been removed from both consumer groups.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The entry was removed from both pending lists; however, the size of the stream remains the same:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This means that the entry is still stored in the string, even though it was processed by all consumer groups. \n",
        "\n",
        "The entry can be deleted with the `XDEL` command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xdel(\"mystream\", message_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we should see the stream size reduced by 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Automating Acknowledged and deletes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In some (or most) use cases, you may not want to preserve an entry after it was processed by all consumer groups, as it could bloat the size of the stream and require more memory. In this case, you can avoid having to take 2 different steps to acknowledge and delete the entry. You could perform both operations with the `XACKDEL` command.\n",
        "\n",
        "<b>IMPORTANT:</b> This is a new command, available with Redis 8.2; if you are running previous versions of Redis, you will need to use different commands to acknowledge and delete entries.\n",
        "\n",
        "The `XACKDEL` command combines the functionality of `XACK` and `XDEL` in Redis Streams. It acknowledges the specified entry IDs in the given consumer group and simultaneously attempts to delete the corresponding entries from the stream. It has a few options as to the criteria that should be used to delete the entry; in this case, we will use the `ACKED` option, which tells Redis to delete this entry if it was already acknowledged by all consumer groups.\n",
        "\n",
        "More information about this command and its options can be found [here](https://redis.io/docs/latest/commands/xackdel/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get the ID to the second pending message in the `myGroupFromEnd` consumer group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pending_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 10, \"Mary\")\n",
        "message_id = pending_entries[0]['message_id']\n",
        "print(message_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's acknowledge this entry with the new `XACKDEL` command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xackdel(\"mystream\", \"myGroupFromEnd\", message_id, ref_policy=\"ACKED\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the Pending lists again, this message should still be pending with the `myGroupFromStart` consumer group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  print(entry)\n",
        "\n",
        "for entry in group2_entries:\n",
        "  print(entry)\n",
        "\n",
        "print(f\"\\n Total: {len(group1_entries) + len(group2_entries)} pending entries - message {message_id} should have been removed from the myGroupFromEnd consumer group.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Meaning, the `XACKDEL` command did what it was supposed to do: acknowledge the message, but only delete it if it's no longer pending in any consumer groups (which is not the case here).\n",
        "\n",
        "Let's run it again, this time for the `myGroupFromStart` consumer group:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xackdel(\"mystream\", \"myGroupFromStart\", message_id, ref_policy=\"ACKED\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's get the list of pending entries and check the stream size:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  print(entry)\n",
        "\n",
        "for entry in group2_entries:\n",
        "  print(entry)\n",
        "\n",
        "print(f\"\\n Total: {len(group1_entries) + len(group2_entries)} pending entries - message {message_id} should have been removed from the myGroupFromEnd consumer group.\")\n",
        "\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, the message was deleted after it was acknowledged."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Trimming Acknowledged Entries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a new capability of Redis 8.2: we can acknowledge entries as they are being processed, and then periodically trim all the entries that have been acknowledged by all consumer groups. The use case here is to give enough time for additional batch jobs or other routines to use the data in these entries, and then batch delete them periodically (daily, weekly, monthly, ...) so they will not be stored permanently.\n",
        "\n",
        "First, let's acknowledge all entries in both consumer groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  message_id = entry['message_id']\n",
        "  r.xack(\"mystream\", \"myGroupFromStart\", message_id)\n",
        "  print(f\"Acknowledged message ID {message_id} from consumer group myGroupFromStart\")\n",
        "\n",
        "\n",
        "for entry in group2_entries:\n",
        "  message_id = entry['message_id']\n",
        "  r.xack(\"mystream\", \"myGroupFromEnd\", message_id)\n",
        "  print(f\"Acknowledged message ID {message_id} from consumer group myGroupFromEnd\")\n",
        "\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the pending entries again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group1_entries = r.xpending_range(\"mystream\", \"myGroupFromStart\", \"-\", \"+\", 100)\n",
        "group2_entries = r.xpending_range(\"mystream\", \"myGroupFromEnd\", \"-\", \"+\", 100)\n",
        "\n",
        "for entry in group1_entries:\n",
        "  print(entry)\n",
        "\n",
        "for entry in group2_entries:\n",
        "  print(entry)\n",
        "\n",
        "print(f\"\\n Total: {len(group1_entries) + len(group2_entries)} pending entries.\")\n",
        "\n",
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " No more pending items, but all entries are still in the stream. Next, let's add one final entry in our stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_message_id = r.xadd(\"mystream\", id=\"*\", fields={\"id\":  13, \"message\": \"cherry\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's trim all the acknowledged entries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xtrim(\"mystream\", maxlen=0, ref_policy=\"ACKED\", approximate=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, check the size of the stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(r.xlen(\"mystream\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZjMFpOF1AOY"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Streams/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Redis insight should be showing a stream with a single entry, and 2 consumer groups with 2 consumers each, and zero pending entries.\n",
        "\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Stream Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will end this lab with a few commands you can use to get information about the stream."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the `XINFO STREAM` command to get general data about the stream:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stream_info = r.xinfo_stream(\"mystream\", full=True)\n",
        "for key, value in stream_info.items():\n",
        "  print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the `XINFO GROUPS` command to get information about groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group_info = r.xinfo_groups(\"mystream\")\n",
        "for group in group_info:\n",
        "  print(group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the `XINFO CONSUMERS` command to get information about consumers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "consumer_info = r.xinfo_consumers(\"mystream\", \"myGroupFromStart\")\n",
        "for consumer in consumer_info:\n",
        "  print(consumer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAVzG-35N0JI"
      },
      "source": [
        "&nbsp;\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4eIa8hN2T9"
      },
      "source": [
        "# Congrats, this is the end of the lab!!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ragdemo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

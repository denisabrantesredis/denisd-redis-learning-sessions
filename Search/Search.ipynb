{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09X5wKjBIsT"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/Search.ipynb\" target=\"_newt\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tk5ymdLBTeq"
      },
      "source": [
        "<div style=\"display:flex;width=100%;\">\n",
        "<img src=\"https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120\" alt=\"Redis\" width=\"90\"/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "</div>\n",
        "\n",
        "# Redis Learning Session - Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/banner.png?raw=true\" alt=\"Redis Data Types\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8w5OAHNOlFf"
      },
      "source": [
        "[Try on online search demo application](https://ecommerce.redisventures.com//)\n",
        "\n",
        "In this notebook, we will explore the different types of Search provided by Redis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENspmGoTR6tq"
      },
      "source": [
        "## Installing the Pre-Reqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFmBBQ0bBFym"
      },
      "outputs": [],
      "source": [
        "!pip install -q folium\n",
        "!pip install -q pandas\n",
        "!pip install -q redis\n",
        "!pip install -q unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing Redis Stack Locally\n",
        "If you are not using Redis Cloud as a database, uncomment and run the code below to install Redis locally. Then set your connection to 127.0.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%sh\n",
        "# curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg \n",
        "# echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list \n",
        "# sudo apt-get update  > /dev/null 2>&1\n",
        "# sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "# redis-stack-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Copying and Unzipping Lab Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(\"files.zip\"):\n",
        "  !wget https://github.com/denisabrantesredis/denisd-redis-learning-sessions/raw/refs/heads/main/_assets/files/files.zip\n",
        "  !unzip files.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connecting to Redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import redis\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Setup the Connection String"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_secrets.png?raw=true\" alt=\"Callout - Use Google Colab secrets instead\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  REDIS_HOST = userdata.get('REDIS_HOST')\n",
        "except:\n",
        "  REDIS_HOST=\"127.0.0.1\"\n",
        "\n",
        "try:\n",
        "  REDIS_PORT = userdata.get('REDIS_PORT')\n",
        "except:\n",
        "  REDIS_PORT=6379\n",
        "\n",
        "try:\n",
        "  REDIS_PASSWORD = userdata.get('REDIS_PASSWORD')\n",
        "except:\n",
        "  REDIS_PASSWORD=\"\"\n",
        "\n",
        "REDIS_URL = f\"redis://default:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing the Connection to Redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_connection.png?raw=true\" alt=\"Callout - Make sure connection works\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = redis.from_url(REDIS_URL)\n",
        "\n",
        "if r.ping():\n",
        "    print(\"Connection successful!\")\n",
        "else:\n",
        "    print(\"Connection issue!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7_A4sOeDfqt"
      },
      "source": [
        "## Geospatial Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ6RwklAct5K"
      },
      "source": [
        "Geospatial data is supported in Redis as a native data type, and as part of our native JSON support. In this lab, we will explore both options.\n",
        "\n",
        "Redis uses coordinate points to represent geospatial locations. You can store individual points but you can also use a set of points to define a polygon shape (the shape of a town, for example). You can query several types of interactions between points and shapes, such as whether a point lies within a shape or whether two shapes overlap."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 1 - Native Geo data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ko4lH56BFs3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import folium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Data\n",
        "\n",
        "For this lab, we will use a dataset containing Airbnb listings and metrics in New York City for January, 2024. Each listing contains coordinates for the location, which is what we are interested in for this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD3zIcq6BFpx"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('./new_york_listings_2024.csv')\n",
        "print(len(dataset))\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Understand the distribution of the Room_Type attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset['room_type'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create a new Dataframe only with Hotel Room records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hotel_rooms = dataset[dataset['room_type'] == 'Hotel room']\n",
        "print(len(hotel_rooms))\n",
        "hotel_rooms.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save data to Redis\n",
        "\n",
        "We will use a pipeline to write data to Redis. The pipeline will gather all commands, and then send the list of commands to the server, where they are executed in order. The pipeline then returns a list containing the response for each command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = r.pipeline(transaction=False)\n",
        "keyname = \"geo:nyc:hotel_rooms\"\n",
        "\n",
        "for index, row in hotel_rooms.iterrows():\n",
        "      lat = row['latitude']\n",
        "      lon = row['longitude']\n",
        "      id = row['id']\n",
        "      pipe.geoadd(keyname, [lon, lat, id])\n",
        "pipe.execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open Redis Insight and confirm that the geo key was generated. There should be only one key, called `geo:nyc:hotel_rooms`, which contains all the different locations from the DataFrame.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Search for Hotel Rooms near the Empire State Building \n",
        "\n",
        "Next, we will search for Hotel Rooms within 850 meters of the Empire State Building, which is located at coordinates 40.7491301,-73.9924523. You can change the "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_georadius.png?raw=true\" alt=\"Callout - Change Search Radius\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "esb_lat = 40.748534150023396\n",
        "esb_lon = -73.98568519949094\n",
        "radius = 850"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run the search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rooms = r.georadius(keyname, esb_lon, esb_lat, radius, 'm', withdist=True, withcoord=True)\n",
        "len(rooms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Render a map to see results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map1 = folium.Map(location=[esb_lat, esb_lon], zoom_start=15, tiles=\"Cartodb Positron\")\n",
        "folium.Marker([esb_lat, esb_lon], popup=\"Empire State Building\", icon=folium.Icon(color='blue')).add_to(map1)\n",
        "folium.Circle(\n",
        "    location=[esb_lat, esb_lon], radius=radius, color=\"cornflowerblue\", weight=1, fill_opacity=0.3, opacity=1, stroke=False,\n",
        "    fill=True, popup=\"{} meters\".format(radius), tooltip=\"Search Radius\"\n",
        ").add_to(map1)\n",
        "\n",
        "for room in rooms:\n",
        "    folium.Marker([room[2][1], room[2][0]], popup=f\"{room[0]} {round(room[1],2)} meters\", icon=folium.Icon(color='red')).add_to(map1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Part 2 - Geospatial data with JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from redis.commands.search.field import GeoShapeField\n",
        "from redis.commands.search.field import TextField\n",
        "from redis.commands.search.field import TagField\n",
        "from redis.commands.search.field import NumericField\n",
        "from redis.commands.search.query import Query\n",
        "from redis.commands.search.index_definition import IndexDefinition, IndexType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save JSON data to Redis\n",
        "\n",
        "In this step, we will save the same data from before, but as JSON format, which will allow us to capture more attributes, not just the coordinates. Notice how the `location` attribute is saved as a `POINT()` record, with longitude and latitude. We need this to run our polygon search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for index, row in hotel_rooms.iterrows():\n",
        "      id = row['id']\n",
        "      keyname = f\"geo:nyc:hotel_rooms:{id}\"\n",
        "      value = {\n",
        "            'id': id,\n",
        "            'location': f\"POINT ({row['longitude']} {row['latitude']})\",\n",
        "            'latitude': row['latitude'],\n",
        "            'longitude': row['longitude'],\n",
        "            'host_name' : row['host_name'],\n",
        "            'neighbourhood': row['neighbourhood'],\n",
        "            'price': row['price'],\n",
        "            'reviews': row['number_of_reviews'],\n",
        "            'rating': row['rating'],\n",
        "            'bedrooms': row['bedrooms']\n",
        "      }\n",
        "      pipe.json().set(keyname, \"$\", value)\n",
        "result = pipe.execute()\n",
        "len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Search Index\n",
        "\n",
        "JSON data needs to be indexed for search. This command will create the search index for the location attribute (which includes the latitude and longitude information)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "geo_schema = (GeoShapeField(\"$.location\", as_name=\"location\"))\n",
        "\n",
        "try:\n",
        "    r.ft(\"idx:rooms\").drop_index()\n",
        "except:\n",
        "    print(\"Index does not exist\")\n",
        "\n",
        "try:\n",
        "  geo_index_create_result = r.ft(\"idx:rooms\").create_index(\n",
        "    geo_schema,\n",
        "    definition=IndexDefinition(\n",
        "        prefix=[\"geo:nyc:hotel_rooms:\"], index_type=IndexType.JSON\n",
        "    )\n",
        "  )\n",
        "  print(geo_index_create_result)\n",
        "\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Check the index\n",
        "\n",
        "Make sure the index is 100% done, and the total of document is > 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check index\n",
        "info = r.ft('idx:rooms').info()\n",
        "print(f\" Percent Indexed: {int(info['percent_indexed'])*100}\")\n",
        "print(f\" Total Documents: {info['num_docs']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shape = \"POLYGON ((-73.9792654 40.7545612, -73.9928266 40.7549838, -73.9988777 40.7489044, -73.9946291 40.7390201, -73.9805099 40.7385324, -73.9746305 40.7464335, -73.9792654 40.7545612))\"\n",
        "params_dict = {\"esb\": shape}\n",
        "\n",
        "q = Query(\"@location:[WITHIN $esb]\").dialect(3)\n",
        "res = r.ft(\"idx:rooms\").search(q, query_params=params_dict).docs\n",
        "print(len(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Equivalent Redis Insight command\n",
        "\n",
        "```\n",
        "    FT.SEARCH idx:rooms \"(@location:[WITHIN $qshape])\" \n",
        "        PARAMS 2 qshape \"POLYGON ((-73.9792654 40.7545612, -73.9928266 40.7549838, -73.9988777 40.7489044, -73.9946291 40.7390201, -73.9805099 40.7385324, -73.9746305 40.7464335, -73.9792654 40.7545612))\" \n",
        "        RETURN 1 name \n",
        "        DIALECT 2\n",
        "```\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Render a new map with the polygon and the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map2 = folium.Map(location=[esb_lat, esb_lon], zoom_start=15, tiles=\"Cartodb Positron\")\n",
        "folium.Marker([esb_lat, esb_lon], popup=\"Empire State Building\", icon=folium.Icon(color='blue')).add_to(map2)\n",
        "\n",
        "locations = [[40.7545612, -73.9792654], [40.7549838, -73.9928266], [40.7489044, -73.9988777], [40.7390201, -73.9946291], [40.7385324, -73.9805099], [40.7464335, -73.9746305], [40.7545612, -73.9792654]]\n",
        "\n",
        "folium.Polygon(locations=locations, color=\"cornflowerblue\", weight=1, fill_opacity=0.3, opacity=1, stroke=False, fill_color=\"maroon\", fill=True, popup=\"Polygon\", tooltip=\"Click me!\",).add_to(map2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for room in res:\n",
        "    room_json = json.loads(room.json)\n",
        "    lat = room_json[0]['latitude']\n",
        "    lon = room_json[0]['longitude']\n",
        "    host_name = room_json[0]['host_name']\n",
        "    price = room_json[0]['price']\n",
        "    # print(room_json[0])\n",
        "    folium.Marker([lat, lon], popup=f\"{host_name} ${price}\", icon=folium.Icon(color='red')).add_to(map2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "map2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Cq6TN1DrIk"
      },
      "source": [
        "## Streams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33RhGtaaduow"
      },
      "source": [
        "A Redis stream is a data structure that acts like an append-only log but also implements several operations to overcome some of the limits of a typical append-only log. These include random access in O(1) time and complex consumption strategies, such as consumer groups. You can use streams to record and simultaneously syndicate events in real time. Examples of Redis stream use cases include:\n",
        "\n",
        "- Event sourcing (e.g., tracking user actions, clicks, etc.)\n",
        "- Sensor monitoring (e.g., readings from devices in the field)\n",
        "- Notifications (e.g., storing a record of each user's notifications in a separate stream)\n",
        "\n",
        "\n",
        "In this example, we will load IoT data from temperature monitoring devices as streams, and look for data within a certain time range. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHd7FtUPBFlE"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import pytz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load data from the CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvoJfpupBFf2"
      },
      "outputs": [],
      "source": [
        "iot_ds = pd.read_csv('iot.csv')\n",
        "print(len(iot_ds))\n",
        "iot_ds.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using a pipeline to save data to Redis\n",
        "\n",
        "All messages will be under a single stream (key), named `stream:iot`. The pipeline will gather all commands and execute them once against Redis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keyname = \"streams:iot\"\n",
        "for index, row in iot_ds.iterrows():\n",
        "      value = {\n",
        "            'id': row['id'],\n",
        "            'room': row['room'],\n",
        "            'date': row['date'],\n",
        "            'temp' : row['temp'],\n",
        "            'location': row['location'],\n",
        "            'timestamp': row['timestamp']\n",
        "      }\n",
        "      pipe.xadd(keyname, id=row['timestamp'], fields=value)\n",
        "result = pipe.execute()\n",
        "len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Getting the first and last timestamps - format DAY/MONTH/YEAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(iot_ds.iloc[0]['date'])\n",
        "print(iot_ds.iloc[len(iot_ds)-1]['date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZkC5BMHEBit"
      },
      "source": [
        "#### Define the time range you want to search on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp6tj60UeOcc"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_streams.png?raw=true\" alt=\"Callout - Change Time Range\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-oiUVRLD3pm"
      },
      "outputs": [],
      "source": [
        "start_date = \"01-04-2024 12:00\"\n",
        "end_date = \"01-04-2024 12:30\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJdvZR-FEIcE"
      },
      "outputs": [],
      "source": [
        "datetime_format = \"%d-%m-%Y %H:%M\"\n",
        "local_tz = pytz.timezone('America/Chicago')\n",
        "\n",
        "local_start = datetime.strptime(start_date, datetime_format)\n",
        "utc_start = local_tz.localize(local_start)\n",
        "first_ts = utc_start.timestamp()\n",
        "\n",
        "local_end = datetime.strptime(end_date, datetime_format)\n",
        "utc_end = local_tz.localize(local_end)\n",
        "last_ts = utc_end.timestamp()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Running the Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = r.xrange(\"streams:iot\", int(first_ts), int(last_ts))\n",
        "for message in messages:\n",
        "  print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use Redis Insight to check on the stream data. There should be a key called `streams:iot` with all 97,546 messages in it. The UI will show some of the messages, and you can run the same search in the Workbench, using this command:\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "```\n",
        "    XRANGE streams:iot 1711972800 1711974600\n",
        "```\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j-_YodJFyZH"
      },
      "source": [
        "## Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGd2WQ9LjK_M"
      },
      "source": [
        "The Redis time series data type lets you store real-valued data points along with the time they were collected. You can combine the values from a selection of time series and query them by time or value range. You can also compute aggregate functions of the data over periods of time and create new time series from the results. When you create a time series, you can specify a maximum retention period for the data, relative to the last reported timestamp, to prevent the time series from growing indefinitely.\n",
        "\n",
        "In this lab, we will load stock data from a few different companies and search for data within a specific time range. The stock data contains the Open and Close values with one data point per day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdCicFUVkb-p"
      },
      "source": [
        "### Importing Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7tb6ImZF247"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq-_RvOKmVr7"
      },
      "source": [
        "#### Load data from CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0H9huxKHI4q"
      },
      "outputs": [],
      "source": [
        "ts_df = pd.read_csv('timeseries.csv')\n",
        "ts_df = ts_df.sort_values(by='Ticker')\n",
        "print(len(ts_df))\n",
        "ts_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Y3Fy_JnSm5"
      },
      "source": [
        "#### Time Series data is accessed through the `r.ts()` object. It has its own pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLUdjv5KHOpJ"
      },
      "outputs": [],
      "source": [
        "redis_ts = r.ts()\n",
        "\n",
        "datetime_format = \"%Y-%m-%d %H:%M:%S%z\"\n",
        "local_tz = pytz.timezone('America/New_York')\n",
        "\n",
        "keyprefix = \"timeseries:stock\"\n",
        "pipets = redis_ts.pipeline(transaction=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_j8oVZIzgvv"
      },
      "source": [
        "Get a list of all stock ticks in the file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g-MMhPNze4Z"
      },
      "outputs": [],
      "source": [
        "ticker_list = ts_df['Ticker'].unique()\n",
        "ticker_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each time series (key) will hold the values of one metric over time. The CSV file contains 2 metrics (Open and Close values) for 5 different stock tickers, which means that we will need to create 10 keys, 2 for each ticker.\n",
        "\n",
        "The loop will first create 2 keys for each ticker in a try statement (because the keys can only be created once), then it will add the Open and Close values to those keys. We will use labels to filter the keys during the search:\n",
        "\n",
        "- Ticker will allow us to filter the search by company (\"give me all Apple stock data, etc)\n",
        "- Type will allow us to select the type of metric (\"give me all Open values for Dec 1st, 2015\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for ticker in ticker_list:\n",
        "    df_loop = ts_df[ts_df['Ticker'] == ticker]\n",
        "    print(f\"Creating Keys for Ticker {ticker} : {len(df_loop)} total rows\")\n",
        "\n",
        "    label_open = {'TICKER' : ticker, 'TYPE': 'open'}\n",
        "    label_close = {'TICKER' : ticker, 'TYPE': 'close'}\n",
        "    keyopen = f\"{keyprefix}:{ticker}:open\"\n",
        "    keyclose = f\"{keyprefix}:{ticker}:close\"\n",
        "\n",
        "    try:\n",
        "      redis_ts.create(keyopen, labels=label_open, duplicate_policy='LAST')\n",
        "      redis_ts.create(keyclose, labels=label_close, duplicate_policy='LAST')\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    values = df_loop.values.tolist()\n",
        "    counter = 0\n",
        "    for value in values:\n",
        "      m_date = value[0]\n",
        "      m_open = value[1]\n",
        "      m_close = value[2]\n",
        "      local_start = datetime.strptime(m_date, datetime_format)\n",
        "      timestamp = int(local_start.timestamp())\n",
        "      \n",
        "      _ = pipets.add(keyopen, timestamp, m_open) \n",
        "      _ = pipets.add(keyclose, timestamp, m_close)\n",
        "      counter += 1\n",
        "      # print(f\"Counter: {counter}\")\n",
        "result = pipets.execute()\n",
        "print(len(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### List the first and last timestamp - date format DAY/MONTH/YEAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(ts_df.iloc[0]['Date'])\n",
        "print(ts_df.iloc[len(ts_df)-1]['Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set the time range and stock ticker for our search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_timeseries.png?raw=true\" alt=\"Callout - Change Time Range and Stock Ticker\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_time = \"2016-05-01 12:00:00-04:00\"\n",
        "end_time = \"2016-05-11 12:00:00-04:00\"\n",
        "ticker = \"AAPL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Retrieve open and close data from the selected stock ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filters = [f\"TICKER=({ticker})\"]\n",
        "start_ts = int(datetime.strptime(start_time, datetime_format).timestamp())\n",
        "end_ts = int(datetime.strptime(end_time, datetime_format).timestamp())\n",
        "results = redis_ts.mrange(from_time=start_ts, to_time=end_ts, filters=filters)\n",
        "len(results[0]['timeseries:stock:AAPL:close'][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Adding the search results to a new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "open_data, close_data = [], []\n",
        "for result in results:\n",
        "  keyname = list(result.keys())[0]\n",
        "  keydata = result[keyname]\n",
        "  if 'open' in keyname:\n",
        "    for item in keydata[1]:\n",
        "      open_data.append((str(datetime.fromtimestamp(item[0]).strftime('%Y-%m-%d %H:%M:%S.%f')[:-16]), item[1]))\n",
        "  else:\n",
        "    for item in keydata[1]:\n",
        "      close_data.append((str(datetime.fromtimestamp(item[0]).strftime('%Y-%m-%d %H:%M:%S.%f')[:-16]), item[1]))\n",
        "\n",
        "df_open = pd.DataFrame(open_data, columns=['Date', 'Open'])\n",
        "df_close = pd.DataFrame(close_data, columns=['Date', 'Close'])\n",
        "df_open.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualizing the search results in a timeline chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5)) \n",
        "plt.plot(df_open['Date'], df_open['Open'], label='Open',)\n",
        "plt.plot(df_close['Date'], df_close['Close'], label='Close')\n",
        "plt.title(f\"{ticker} - Open\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jHy0dVgsAAg"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDX0QOboqped"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-redis-learning-sessions/blob/main/Search/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxBu0RKZqu4t"
      },
      "source": [
        "Open Redis Insight and confirm that all documents were generated. Notice how each document contains the vector that was automatically generated by the Langchain package. You may also notice that the vectors are not presented as a list; this is due to the fact that they are stored as binary strings, which is more efficient for retrieval and storage.\n",
        "\n",
        "You can also go to the **Workbench** and get a list of indexes using the command:\n",
        "\n",
        "```\n",
        "FT._list\n",
        "```\n",
        "\n",
        "Finally, you can get more details about the index that was automatically generated by Langchain with this command:\n",
        "```\n",
        "FT.info \"idx:web\"\n",
        "```\n",
        "&nbsp;\n",
        "\n",
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__zfLJoaHa13"
      },
      "source": [
        "## Part 4: Running a Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjpqcmh8vGFP"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_question.png?raw=true\" alt=\"Callout - Change Question\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "249O38igHeb1"
      },
      "outputs": [],
      "source": [
        "query = \"How does Redis Insight make RDI simpler?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3kewVQvR8y"
      },
      "source": [
        "### Running a Semantic Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4WSqBSVvZCV"
      },
      "source": [
        "The Langchain integration greatly simplifies the process of running a semantic search. A single function call is enough. Notice how we do not need to generate a vector for our question manually; this is handled automatically by the function, based on the embedding model we've selected before.\n",
        "\n",
        "For more details on the different ways to run vector searches, check the [Langchain documentation page](https://python.langchain.com/docs/integrations/vectorstores/redis/#query-vector-store).\n",
        "\n",
        "&nbsp;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-n9ER0lHi12"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "results = vector_store.similarity_search_with_score(query)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FKaU45iwULg"
      },
      "source": [
        "### Visualizing the search results with the score for each result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wepEg9G0umFH"
      },
      "outputs": [],
      "source": [
        "print(f\"Search results for '{query}':\")\n",
        "for doc in results:\n",
        "    print(\"----\")\n",
        "    print(f\"Score: {doc[1]} - {doc[0].page_content} (Source: {doc[0].metadata['url']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZUaPXegyFyx"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UALXxSxHHugw"
      },
      "source": [
        "## Part 5: Using a LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC3h0h55yKKJ"
      },
      "source": [
        "In this lab, we will use the Gemini Pro 1.5 model from Google to generate a response to the user, based on the documents retrieved from Redis. The GCP API Key that we set before is required to allow access to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3UgzWI31G6P"
      },
      "source": [
        "### Step 1: Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAMSsoWgHw2u"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDNxn4XlIc6T"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0.5,\n",
        "    top_p=0.95,\n",
        "    top_k=64,\n",
        "    max_output_tokens=8192\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dazMdtlQIi6Z"
      },
      "source": [
        "### Step 2: Prepare a list with the text from the documents retrieved by the vector search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODF9JrNwz7Pu"
      },
      "source": [
        "We will ask the model to respond to the user's questions. To help with the answer, we want to provide the text from the documents that were retrieved by the semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vptTC1f8Imo7"
      },
      "outputs": [],
      "source": [
        "text_list = []\n",
        "distance_list = []\n",
        "\n",
        "for node in results:\n",
        "    text_list.append(node[0].page_content)\n",
        "    distance = node[1]\n",
        "    distance_list.append(distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnQaXkij0GsC"
      },
      "source": [
        "Print the list that will be sent to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJ0cxZ3AIpax"
      },
      "outputs": [],
      "source": [
        "text_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wyvpWAdIscB"
      },
      "source": [
        "### Step 3: Prepare the Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBeR4rv80Qhr"
      },
      "source": [
        "Since this is just a lab, we will keep the prompt very simple, with just basic instructions for the model to answer based on the documents from the semantic search, and to stick to the documents for the response. Production prompts will benefit from more sophisticated prompts, as well as other controls like guardrails, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HJjxxOcIuGy"
      },
      "outputs": [],
      "source": [
        "def get_system_template(text_list, query):\n",
        "  system_template = \"\"\"\n",
        "  Your task is to answer questions by using a given context.\n",
        "\n",
        "  Don't invent anything that is outside of the context.\n",
        "\n",
        "  %CONTEXT%\n",
        "  {context}\n",
        "\n",
        "  \"\"\"\n",
        "  messages = [\n",
        "      SystemMessage(content=system_template.format(context=text_list)),\n",
        "      HumanMessage(content=query)\n",
        "  ]\n",
        "\n",
        "  return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaezsB6k0zxv"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FtObK5_Iwmq"
      },
      "source": [
        "### Step 4: Invoke the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQjHLVPk5tL7"
      },
      "source": [
        "Since we are not using Redis as cache, the model will be called every time, even if the same question (or a similar) is asked multiple times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QpDbPJCIzGE"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZjMFpOF1AOY"
      },
      "source": [
        "Visualizing the model response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeCGJit20POh"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX9qkKbB526_"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh-IMpo8JdB7"
      },
      "source": [
        "## Part 6: Leveraging Redis for Basic Cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFYrtKhb55KA"
      },
      "source": [
        "Redis can be used not only as the Vector Database, but also as a cache to store responses from the Large Language Model, which can significantly improve user experience, by retrieving responses in milliseconds instead of seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4kBM-GDJg4h"
      },
      "outputs": [],
      "source": [
        "from langchain_redis import RedisCache\n",
        "from langchain.globals import set_llm_cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apl2cosa6oLR"
      },
      "source": [
        "To use Redis as a cache, we only need 2 lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtWde9w_J0sQ"
      },
      "outputs": [],
      "source": [
        "redis_cache = RedisCache(redis_url=REDIS_URL)\n",
        "set_llm_cache(redis_cache)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eEryVNs6qay"
      },
      "source": [
        "We will repeat the same question from before. Since we have just enabled the cache, it will be empty, which means that this next question will require a vector search and will need to go through the Large Language Model again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OGmcuaaKF75"
      },
      "outputs": [],
      "source": [
        "query = \"How does Redis Insight make RDI simpler?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt_wqC2yKM3Y"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "result_nodes = vector_store.similarity_search_with_score(query)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfgHUnJx7EqP"
      },
      "source": [
        "Prepare the list of texts to send to the LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChKJ5TivKWeA"
      },
      "outputs": [],
      "source": [
        "text_list = []\n",
        "distance_list = []\n",
        "\n",
        "for node in result_nodes:\n",
        "    text_list.append(node[0].page_content)\n",
        "    distance = node[1]\n",
        "    distance_list.append(distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs9QcQN97I_g"
      },
      "source": [
        "Display the search results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBHp5BiHKjIp"
      },
      "outputs": [],
      "source": [
        "print(f\"--> Total Documents Found: {len(result_nodes)}\")\n",
        "for node in result_nodes:\n",
        "  print(f\"--> {node[1]} | {node[0].page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBH1nheo7L7v"
      },
      "source": [
        "Prepare the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JBZHBpKMIV_"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkKG8oR17OKU"
      },
      "source": [
        "Call the model (the `invoke` function will check and populate the cache automatically):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7at9YHOWKG6"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URIIB4Hy7WrH"
      },
      "source": [
        "Print the LLM response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipERjc1aRcCC"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6oBBqwS7haw"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJakv8xO7i8Q"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp36z0d-7hR7"
      },
      "source": [
        "A new document should appear on Redis, of type JSON. This is the cached response from the LLM.\n",
        "Notice that the key is made from a long this; this is a hash of the question.\n",
        "\n",
        "Because this is a basic cache, questions from the user will be hashed and compared against the key, which means that for this basic cache, questions must match exactly in order to be used.\n",
        "\n",
        "&nbsp;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemlQkpZNLx-"
      },
      "source": [
        "#### Repeating the question to fetch results from the cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvHXlFXL8y5Z"
      },
      "source": [
        "When we ask exactly the same question as before, it should trigger a cache hit, meaning we will receive the answer from the Redis cache, much faster than calling the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV4r9h-9NOcP"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btlVe7qM9G7T"
      },
      "source": [
        "Print the cached response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDGRpcHORY93"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4sszbPX9KXm"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4R86mhmNhuT"
      },
      "source": [
        "#### Asking the same question (worded differently) will cause a cache miss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZmHsS8t9MkC"
      },
      "source": [
        "If the question is not an exact match, it will cause a cache miss. This might be an issue with most of the RAG use cases, which is why we will be exploring Semantic Cache next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhRX_GoHNmuW"
      },
      "outputs": [],
      "source": [
        "# original query = \"How does Redis Insight make RDI simpler?\"\n",
        "query = \"What does Redis Insight do to make RDI simpler?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHQq4Shr_ZKf"
      },
      "source": [
        "Prepare the prompt with the new query (PS: we're skipping the vector search on purpose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCFhpjBgNwVa"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_JTMxC8_i9E"
      },
      "source": [
        "Call the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hogIqAOnNwQh"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9W1P_M6_mDp"
      },
      "source": [
        "Print the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzO7OAVoNwJt"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPVB6DDX_1LG"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbNoHMtFN45X"
      },
      "source": [
        "## Part 7 - Leveraging Redis for Semantic Cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwR5FEo2AJjK"
      },
      "source": [
        "The Semantic Cache will generate vectors for each prompt, and store the response from the LLM. That way, new prompts are converted into vectors automatically and a semantic search is executed on Redis, looking for similar questions.\n",
        "\n",
        "It is possible to set the threshold for for semantic search; for this lab, we are using 20%. In your project, you can run multiple tests with different thresholds, to determined what works best for your use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFuDm3vwOCJg"
      },
      "outputs": [],
      "source": [
        "from langchain_redis import RedisSemanticCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv75yqFrAqry"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_threshold.png?raw=true\" alt=\"Callout - Semantic Threshold\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA-yaqYtN-bR"
      },
      "outputs": [],
      "source": [
        "redis_cache = RedisSemanticCache(redis_url=REDIS_URL, embeddings=embeddings, distance_threshold=0.2)\n",
        "set_llm_cache(redis_cache)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6nR-AFBEVZ"
      },
      "source": [
        "Since the Semantic Cache is new, it will be empty. We will ask the original question first, to generate the cache entry:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm3SLk2u-SWn"
      },
      "outputs": [],
      "source": [
        "query = \"How does Redis Insight make RDI simpler?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjeCV10VBMD8"
      },
      "source": [
        "Prepare the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Pvy352-Rsb"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWKkgnnoBO-d"
      },
      "source": [
        "Invoke the model (it will cause a cache miss):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJGYVojmWUdB"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--0PfUm1BUa8"
      },
      "source": [
        "Print the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heR894L4-lHd"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVN4Q2MBYOQ"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoqlHw8DO0zL"
      },
      "source": [
        "<img src=\"https://github.com/denisabrantesredis/denisd-GenAI-Workshop/blob/main/_assets/images/callout_insight.png?raw=true\" alt=\"Callout - Check Redis Insight\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoO1iZmVO1zW"
      },
      "source": [
        "A new Hash document will appear in Redis, with a key prefix of `llmcache`. This is the cached prompt, which includes the question and the answer. The `invoke` function will run a semantic search for these documents, to look for similar questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDfgdGQnO_ci"
      },
      "source": [
        "&nbsp;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3iZspjDQc_b"
      },
      "source": [
        "#### Ask a similar question to trigger a cache hit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1dac3x9QV-h"
      },
      "outputs": [],
      "source": [
        "query = \"What does Redis Insight do to make RDI simpler?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5WV9CfJBedI"
      },
      "source": [
        "Prepare the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6ekUthmQXVh"
      },
      "outputs": [],
      "source": [
        "messages = get_system_template(text_list, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Syj2_WBgTC"
      },
      "source": [
        "Invoke the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNeUsew8QXSu"
      },
      "outputs": [],
      "source": [
        "timer_start = time.perf_counter()\n",
        "llm_response = llm.invoke(messages)\n",
        "timer_end = time.perf_counter()\n",
        "total_time = round(timer_end - timer_start, 4)\n",
        "print(f\"Total Time: {total_time}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e78ba7Y5Bi66"
      },
      "source": [
        "Print the response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt_hlPsRQXQE"
      },
      "outputs": [],
      "source": [
        "llm_response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Search examples\n",
        "\n",
        "# Time rollup with distinct users by hour\n",
        "# FT.AGGREGATE myIndex \"*\" \n",
        "#   APPLY \"@timestamp - (@timestamp % 3600)\" AS hour \n",
        "#   GROUPBY 1 @hour \n",
        "#   REDUCE COUNT_DISTINCT 1 @user_id AS num_users \n",
        "#   SORTBY 2 @hour ASC \n",
        "#   APPLY timefmt(@hour) AS hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multiple reducers under one GROUPBY\n",
        "# FT.AGGREGATE products \"*\" \n",
        "#   GROUPBY 1 @category \n",
        "#   REDUCE COUNT 0 AS product_count \n",
        "#   REDUCE SUM 1 @price AS total_price \n",
        "#   REDUCE AVG 1 @rating AS avg_rating \n",
        "#   SORTBY 2 @total_price DESC \n",
        "#   LIMIT 0 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derived fields, then aggregate revenue by category\n",
        "# FT.AGGREGATE products \"*\" \n",
        "#   LOAD 3 @price @discount @quantity \n",
        "#   APPLY \"@price - @discount\" AS final_price \n",
        "#   APPLY \"@final_price * @quantity\" AS total_revenue \n",
        "#   GROUPBY 1 @category \n",
        "#   REDUCE SUM 1 @total_revenue AS total_category_revenue \n",
        "#   SORTBY 2 @total_category_revenue DESC \n",
        "#   LIMIT 0 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Post-aggregation filtering on a reduced value\n",
        "# FT.AGGREGATE idx \"*\" \n",
        "#   GROUPBY 1 @foo \n",
        "#   REDUCE COUNT 0 AS num \n",
        "#   FILTER \"@num < 100\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Geo distance compute and sort\n",
        "# FT.AGGREGATE libraries-idx \"@location:[-73.982254 40.753181 10 km]\" \n",
        "#   LOAD 1 @location \n",
        "#   APPLY \"geodistance(@location, -73.982254, 40.753181)\" AS dist \n",
        "#   SORTBY 2 @dist ASC \n",
        "#   LIMIT 0 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parameterized filters with DIALECT 2\n",
        "# FT.AGGREGATE products \"*\" \n",
        "#   LOAD 3 @price @rating @quantity \n",
        "#   FILTER \"@price >= $minp\" \n",
        "#   FILTER \"@rating >= $minr\" \n",
        "#   APPLY \"@price * @quantity\" AS total_value \n",
        "#   SORTBY 2 @total_value DESC \n",
        "#   LIMIT 0 10 \n",
        "#   DIALECT 2 \n",
        "#   PARAMS 4 minp 500 minr 4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Faceted counts (split TAG-like field to facets)\n",
        "# Example flow: APPLY split(@category) AS ctg -> GROUPBY @ctg -> REDUCE COUNT AS num_per_ctg -> SORTBY @num_per_ctg DESC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Portfolio analytics (business calc)\n",
        "# FT.AGGREGATE idx_trading_security_lot \"@accountNo:(ACC10001) @date:[0 1725186610]\" \n",
        "#   GROUPBY 1 @ticker \n",
        "#   REDUCE SUM 1 @lotValue AS totalLotValue \n",
        "#   REDUCE SUM 1 @quantity AS totalQuantity \n",
        "#   APPLY \"(@totalLotValue/(@totalQuantity*100))\" AS avgPrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hybrid vector + text with ADDSCORES and derived scores\n",
        "# FT.AGGREGATE idx:rpv \"(@currency:{USD} ~@brand:(nike) ~@retailer:((walmart)) \n",
        "#                       ~@title:(red | shoes) ~@description:(red | shoes))=>[KNN 2400 @text_vector32 $vector AS vector_distance]\" ADDSCORES \n",
        "#   LOAD 5 title brand price currency retailer_display_name \n",
        "#   APPLY \"(2 - @vector_distance)/2\" AS cosine_similarity \n",
        "#   APPLY @__score AS bm25_score \n",
        "#   APPLY \"0.3@bm25_score + 0.7@cosine_similarity\" AS hybrid_score \n",
        "#   SORTBY 2 @hybrid_score DESC \n",
        "#   LIMIT 0 100 \n",
        "#   PARAMS 2 vector \"<BLOB>\" \n",
        "#   DIALECT 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ordering and placement rules (quick references)\n",
        "# • LOAD must be before the first GROUPBY; loading after aggregation will error. \n",
        "# • Typical order: FILTER → LOAD → APPLY → GROUPBY → REDUCE → SORTBY → LIMIT; DIALECT at end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAVzG-35N0JI"
      },
      "source": [
        "&nbsp;\n",
        "\n",
        "\n",
        "&nbsp;\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G4eIa8hN2T9"
      },
      "source": [
        "# Congrats, this is the end of the lab!!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
